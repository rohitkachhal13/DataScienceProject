{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d7fa86",
   "metadata": {},
   "source": [
    "### 1. Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14aaee28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb0933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications. vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd567e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "b_size = 16\n",
    "CHANNELS = 3\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad7a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1209 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"Pictures\",\n",
    "    shuffle = True,\n",
    "    image_size = (img_size, img_size),\n",
    "    batch_size = b_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# Directory with Jeans pictures\n",
    "jeans_dir = os.path.join(r'C:\\Users\\HP\\Pictures\\img\\train\\jeans')\n",
    "\n",
    "# Directory with Saree pictures\n",
    "saree_dir = os.path.join(r'C:\\Users\\HP\\Pictures\\img\\train\\sarees')\n",
    "\n",
    "# Directory with Trouser pictures\n",
    "trousers_dir = os.path.join(r'C:\\Users\\HP\\Pictures\\img\\train\\trousers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_jeans_names = os.listdir(jeans_dir)\n",
    "print(train_jeans_names[:5])\n",
    "\n",
    "train_saree_names = os.listdir(saree_dir)\n",
    "print(train_saree_names[:5])\n",
    "\n",
    "train_trousers_names = os.listdir(trousers_dir)\n",
    "print(train_trousers_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of Training Images\")\n",
    "print(\"No.of Images of Sarees in train dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\train\\sarees')))\n",
    "print(\"No.of Images of Jeans in train dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\train\\jeans')))\n",
    "print(\"No.of Images of Trousers in train dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\train\\trousers')))\n",
    "print()\n",
    "print(\"Count of Test Images\")\n",
    "print(\"No.of Images of Sarees in test dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\sarees')))\n",
    "print(\"No.of Images of Jeans in test dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\jeans')))\n",
    "print(\"No.of Images of Trousers in test dataset :\",len(os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\trousers')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae436de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=r'C:\\Users\\HP\\Pictures\\img\\train'\n",
    "test_data=r'C:\\Users\\HP\\Pictures\\img\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(240,240,3)\n",
    "batch_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa07735",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_datagen=ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cc773",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set=Train_datagen.flow_from_directory(train_data,\n",
    "                                                              target_size=(240,240),\n",
    "                                                              batch_size=32, \n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb9848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "Test_set=Test_datagen.flow_from_directory(test_data,\n",
    "                                                  target_size=(240,240),\n",
    "                                                  batch_size=5, \n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb22ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c353371",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [240,240]\n",
    "\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# don't train existing weights\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for getting number of classes\n",
    "folders = glob(r'C:\\Users\\HP\\Pictures\\img\\train\\*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 240 * 240 with 3 bytes color\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(240,240, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(240,240, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # 3 output neurons for 3 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fac824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ed9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sample = Training_set.n\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b46ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "        Training_set, \n",
    "        steps_per_epoch=int(total_sample/batch_size),  \n",
    "        epochs=n_epochs,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f721aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking 5 images to predict first\n",
    "test_jeans = os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\jeans')[:5]\n",
    "print(test_jeans)\n",
    "test_sarees = os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\sarees')[:5]\n",
    "print(test_sarees)\n",
    "test_trousers = os.listdir(r'C:\\Users\\HP\\Pictures\\img\\test\\trousers'')[:5]\n",
    "print(test_trousers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d993f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories = [\"Jeans\", \"Sarees\", \"Trousers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c588e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(Test_set.classes)  # Unique Values of the Classes to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39213bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\test\\jeans/'\n",
    "for img_name in test_jeans:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    plt.imshow(img_test)\n",
    "    plt.show()  # Plotting the input Test Image\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da54b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\test\\sarees/'\n",
    "for img_name in test_sarees:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    plt.imshow(img_test)\n",
    "    plt.show()  # Plotting the input Test Image\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\test\\trousers'\n",
    "for img_name in test_trousers:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    plt.imshow(img_test)\n",
    "    plt.show()  # Plotting the input Test Image\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8687579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\train\\jeans/'\n",
    "test_jeans = os.listdir(path)\n",
    "result_jeans = []\n",
    "for img_name in test_jeans:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    #print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    result_jeans.append(Categories[int(np.argmax(model.predict(img_test)))])\n",
    "print(result_jeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\train\\sarees/'\n",
    "test_saree = os.listdir(path)\n",
    "result_saree = []\n",
    "for img_name in test_saree:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    #print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    result_saree.append(Categories[int(np.argmax(model.predict(img_test)))])\n",
    "print(result_saree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\HP\\Pictures\\img\\train\\trousers'\n",
    "test_trouser = os.listdir(path)\n",
    "result_trouser = []\n",
    "for img_name in test_trouser:\n",
    "    img_test=Image.open(path + img_name)\n",
    "    img_test = img_test.resize((240,240))    \n",
    "    img_test=np.expand_dims(img_test,axis=0) # Expand dimensions for proper prediction\n",
    "    #print(\"Predicted as: \",Categories[int(np.argmax(model.predict(img_test)))])  # Predicting Classes using the Model\n",
    "    result_trouser.append(Categories[int(np.argmax(model.predict(img_test)))])\n",
    "print(result_trouser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined all the outputs\n",
    "result = []\n",
    "result = result_jeans+result_saree+result_trouser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "result = LabelEncoder().fit_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34564bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing expected output\n",
    "original = []\n",
    "for i in range(105):\n",
    "    if(i<=34):\n",
    "        original.append(0)\n",
    "    elif(i<=69):\n",
    "        original.append(1)\n",
    "    else:\n",
    "        original.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbed8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score, classification_report\n",
    "print(accuracy_score(result,original)) #accuracy score\n",
    "print(confusion_matrix(result,original)) #confusion matrix\n",
    "print(classification_report(result,original)) #Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f81a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99899342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
